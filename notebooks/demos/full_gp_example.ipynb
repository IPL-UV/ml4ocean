{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full GP Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, ConstantKernel, RBF\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import time as time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/emmanuel/.conda/envs/sci_py36/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Make Fake Dataset\n",
    "X, y = make_regression(\n",
    "    n_samples=10000, \n",
    "    n_features=50,    # Total Features\n",
    "    n_informative=10,   # Informative Features \n",
    "    n_targets=10,\n",
    "    bias=3,\n",
    "    noise=0.8,\n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "# Training and Testing\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, y, train_size=1000, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - MultiOutput w. PCA Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel function\n",
    "kernel = ConstantKernel() * RBF() + WhiteKernel()\n",
    "\n",
    "# define GP model\n",
    "gp_model = GaussianProcessRegressor(\n",
    "    kernel=kernel,            # kernel function (very important)\n",
    "    normalize_y=True,         # good standard practice\n",
    "    random_state=123,         # reproducibility\n",
    "    n_restarts_optimizer=10,  # good practice (avoids local minima)\n",
    ")\n",
    "\n",
    "# Define target transformer\n",
    "pca_model = PCA(n_components=10)\n",
    "\n",
    "# Define Wrapper for target transformation\n",
    "full_regressor = TransformedTargetRegressor(\n",
    "    regressor=gp_model,\n",
    "    transformer=pca_model,   # same number of components as informative\n",
    "    check_inverse=False                 # PCA is not a direct inverse transformation\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "# train GP Model\n",
    "t0 = time.time()\n",
    "full_regressor.fit(X, y)\n",
    "t1 = time.time() - t0\n",
    "\n",
    "# Predictions\n",
    "ypred, ystd = full_regressor.predict(X_plot, return_std=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Stats\n",
    "mae = mean_absolute_error(ypred, ytest)\n",
    "mse = mean_squared_error(ypred, ytest)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(ypred, ytest)\n",
    "\n",
    "print(\n",
    "    f\"MAE: {mae:.3f}\\nMSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\" \n",
    "    f\" \\nTime: {t1:.3} seconds\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GP - Multitask w. PCA Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernel function\n",
    "kernel = ConstantKernel() * RBF() + WhiteKernel()\n",
    "\n",
    "# define GP model\n",
    "gp_model = GaussianProcessRegressor(\n",
    "    kernel=kernel,            # kernel function (very important)\n",
    "    normalize_y=True,         # good standard practice\n",
    "    random_state=123,         # reproducibility\n",
    "    n_restarts_optimizer=10,  # good practice (avoids local minima)\n",
    ")\n",
    "\n",
    "# Define target transformer\n",
    "pca_model = PCA(n_components=10)\n",
    "\n",
    "# Define Wrapper for target transformation\n",
    "full_regressor = TransformedTargetRegressor(\n",
    "    regressor=gp_model,\n",
    "    transformer=pca_model,   # same number of components as informative\n",
    "    check_inverse=False                 # PCA is not a direct inverse transformation\n",
    "\n",
    ")\n",
    "\n",
    "# Define MultiOutput Wrapper\n",
    "model_multi = MultiOutputRegressor(\n",
    "    LinearRegression(), \n",
    "    n_jobs=-1,              # Number of cores to use to parallelize the training\n",
    ")\n",
    "\n",
    "# Train Model\n",
    "t0 = time.time()\n",
    "model_multi.fit(xtrain, ytrain)\n",
    "t1 = time.time() - t0\n",
    "ypred = linear_model_multi.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Stats\n",
    "mae = mean_absolute_error(ypred, ytest)\n",
    "mse = mean_squared_error(ypred, ytest)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(ypred, ytest)\n",
    "\n",
    "print(\n",
    "    f\"MAE: {mae:.3f}\\nMSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\" \n",
    "    f\" \\nTime: {t1:.3} seconds\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sci_py36]",
   "language": "python",
   "name": "conda-env-sci_py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
