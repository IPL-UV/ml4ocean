{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster-Based Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I will be looking at how we can use clustering methods to help us do regression. We will be looking at two approaches:\n",
    "1. Clustering of the data and then training a model per cluster\n",
    "2. Clustering only of the outputs and then training a model per cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.utils import gen_even_slices\n",
    "import time as time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/home/emmanuel/projects/2020_ml_ocn/ml4ocean/src')\n",
    "from data.make_dataset import DataLoad\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_path = '/media/disk/erc/papers/2019_ML_OCN/data/raph_temp_data_NA/'\n",
    "# data_path = '/Users/eman/Documents/data/ocean/‚Å©'\n",
    "\n",
    "# Import data\n",
    "dataloader = DataLoad()\n",
    "\n",
    "X, y = dataloader.load_control_data('na')\n",
    "\n",
    "X = X[dataloader.core_vars]\n",
    "y = y.drop(dataloader.meta_vars, axis=1)\n",
    "\n",
    "# y = np.exp(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(\n",
    "    X, y, train_size=0.8, random_state=123\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize Inputs (per dimension)\n",
    "x_mean, x_std = xtrain.mean(axis=0), xtrain.std(axis=0)\n",
    "\n",
    "xtrain_norm = (xtrain - x_mean) / x_std\n",
    "xtest_norm = (xtest - x_mean) / x_std\n",
    "\n",
    "# Normalize Outputs\n",
    "y_mean = ytrain.mean(axis=0)\n",
    "\n",
    "ytrain_norm = ytrain - y_mean\n",
    "ytest_norm = ytest - y_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method I - Clustering the Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(init='k-means++', n_clusters=3, n_init=10, verbose=None)\n",
    "\n",
    "clf.fit(xtrain_norm)\n",
    "\n",
    "clusters = clf.predict(xtrain_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 1\n",
      "Training Time: 3.689 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: 0.177 \n",
      "Time: 0.783 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: 2\n",
      "Training Time: 2.454 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: 0.243 \n",
      "Time: 0.823 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: 3\n",
      "Training Time: 2.481 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.001\n",
      "R2: 0.133 \n",
      "Time: 0.811 seconds\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "for imodel in np.unique(clusters):\n",
    "    \n",
    "    print(f\"Cluster: {imodel+1}\")\n",
    "    # get subset of data which resides in cluster\n",
    "    ix = xtrain_norm[clusters == imodel]\n",
    "    iy = ytrain_norm[clusters == imodel]\n",
    "    \n",
    "#     print(ix.shape, iy.shape)\n",
    "    \n",
    "    # training and testing split\n",
    "    train_size = 0.8\n",
    "    random_state = 123\n",
    "\n",
    "    ixtrain, ixtest, iytrain, iytest = train_test_split(\n",
    "        ix, iy, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Standardize Inputs (per dimension)\n",
    "    x_mean, x_std = ixtrain.mean(axis=0), ixtrain.std(axis=0)\n",
    "\n",
    "    ixtrain_norm = (ixtrain - x_mean) / x_std\n",
    "    ixtest_norm = (ixtest - x_mean) / x_std\n",
    "\n",
    "    # Normalize Outputs\n",
    "    y_mean = iytrain.mean(axis=0)\n",
    "\n",
    "    iytrain_norm = iytrain - y_mean\n",
    "    iytest_norm = iytest - y_mean\n",
    "    \n",
    "    # =======================\n",
    "    # PCA\n",
    "    # =======================\n",
    "    n_components = 20\n",
    "\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "\n",
    "    iytrain_red = pca_model.fit_transform(iytrain_norm)\n",
    "    iytest_red = pca_model.transform(iytest_norm)\n",
    "    \n",
    "    # =======================\n",
    "    # ML Algorithm\n",
    "    # =======================\n",
    "    rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000, \n",
    "    criterion='mse',\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    warm_start=False,\n",
    "    verbose=0\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    rf_model.fit(ixtrain_norm, iytrain_red)\n",
    "    t1 = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"Training Time: {t1:.3f} seconds\"\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    t0 = time.time()\n",
    "    iypred_red = rf_model.predict(ixtest_norm)\n",
    "    t1 = time.time() - t0\n",
    "    iypred = pca_model.inverse_transform(iypred_red)\n",
    "\n",
    "\n",
    "    # Get Average Stats\n",
    "    mae = mean_absolute_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    mse = mean_squared_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    print(\n",
    "        f\"MAE: {mae:.3f}\\nMSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\" \n",
    "        f\" \\nTime: {t1:.3} seconds\"\n",
    "    )\n",
    "    print(\"Done!\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method II - Clustering the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KMeans(init='k-means++', n_clusters=3, n_init=20, verbose=None)\n",
    "\n",
    "clf.fit(ytrain_norm)\n",
    "\n",
    "clusters = clf.predict(ytrain_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 1\n",
      "(854, 8) (854, 276)\n",
      "Training Time: 2.879 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.155 \n",
      "Time: 0.805 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: 2\n",
      "(1299, 8) (1299, 276)\n",
      "Training Time: 3.086 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: 0.244 \n",
      "Time: 0.802 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: 3\n",
      "(264, 8) (264, 276)\n",
      "Training Time: 2.260 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.001\n",
      "R2: 0.055 \n",
      "Time: 0.851 seconds\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "for imodel in np.unique(clusters):\n",
    "    \n",
    "    print(f\"Cluster: {imodel+1}\")\n",
    "    # get subset of data which resides in cluster\n",
    "    ix = xtrain_norm[clusters == imodel]\n",
    "    iy = ytrain_norm[clusters == imodel]\n",
    "    \n",
    "#     print(ix.shape, iy.shape)\n",
    "    \n",
    "    # training and testing split\n",
    "    train_size = 0.8\n",
    "    random_state = 123\n",
    "\n",
    "    ixtrain, ixtest, iytrain, iytest = train_test_split(\n",
    "        ix, iy, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(ix.shape, iy.shape)\n",
    "    \n",
    "    # Standardize Inputs (per dimension)\n",
    "    x_mean, x_std = ixtrain.mean(axis=0), ixtrain.std(axis=0)\n",
    "\n",
    "    ixtrain_norm = (ixtrain - x_mean) / x_std\n",
    "    ixtest_norm = (ixtest - x_mean) / x_std\n",
    "\n",
    "    # Normalize Outputs\n",
    "    y_mean = iytrain.mean(axis=0)\n",
    "\n",
    "    iytrain_norm = iytrain - y_mean\n",
    "    iytest_norm = iytest - y_mean\n",
    "    \n",
    "    # =======================\n",
    "    # PCA\n",
    "    # =======================\n",
    "    n_components = 20\n",
    "\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "\n",
    "    iytrain_red = pca_model.fit_transform(iytrain_norm)\n",
    "    iytest_red = pca_model.transform(iytest_norm)\n",
    "    \n",
    "    # =======================\n",
    "    # ML Algorithm\n",
    "    # =======================\n",
    "    rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000, \n",
    "    criterion='mse',\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    warm_start=False,\n",
    "    verbose=0\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    rf_model.fit(ixtrain_norm, iytrain_red)\n",
    "    t1 = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"Training Time: {t1:.3f} seconds\"\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    t0 = time.time()\n",
    "    iypred_red = rf_model.predict(ixtest_norm)\n",
    "    t1 = time.time() - t0\n",
    "    iypred = pca_model.inverse_transform(iypred_red)\n",
    "\n",
    "\n",
    "    # Get Average Stats\n",
    "    mae = mean_absolute_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    mse = mean_squared_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    print(\n",
    "        f\"MAE: {mae:.3f}\\nMSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\" \n",
    "        f\" \\nTime: {t1:.3} seconds\"\n",
    "    )\n",
    "    print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method III - Binning the Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2417, 75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain_norm.values[:, :75].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = [\n",
    "    (0, 90), (90, 180), (180, 276)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(0, 28, None)\n"
     ]
    }
   ],
   "source": [
    "for i in gen_even_slices(ytrain_norm.shape[1], 10):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: slice(0, 28, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 4.667 seconds\n",
      "MAE: 0.001\n",
      "MSE: 0.000\n",
      "RMSE: 0.001\n",
      "R2: 0.143 \n",
      "Time: 0.804 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(28, 56, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 3.902 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.034 \n",
      "Time: 0.788 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(56, 84, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 2.248 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.022 \n",
      "Time: 0.803 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(84, 112, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 2.149 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: 0.000 \n",
      "Time: 0.773 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(112, 140, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 1.942 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.002 \n",
      "Time: 0.788 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(140, 168, None)\n",
      "(2417, 8) (2417, 28)\n",
      "Training Time: 2.003 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.004 \n",
      "Time: 0.793 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(168, 195, None)\n",
      "(2417, 8) (2417, 27)\n",
      "Training Time: 1.950 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.006 \n",
      "Time: 0.899 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(195, 222, None)\n",
      "(2417, 8) (2417, 27)\n",
      "Training Time: 1.893 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.017 \n",
      "Time: 0.32 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(222, 249, None)\n",
      "(2417, 8) (2417, 27)\n",
      "Training Time: 1.967 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.027 \n",
      "Time: 0.82 seconds\n",
      "Done!\n",
      "\n",
      "Cluster: slice(249, 276, None)\n",
      "(2417, 8) (2417, 27)\n",
      "Training Time: 2.164 seconds\n",
      "MAE: 0.000\n",
      "MSE: 0.000\n",
      "RMSE: 0.000\n",
      "R2: -0.032 \n",
      "Time: 0.796 seconds\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model 1\n",
    "for idx in gen_even_slices(ytrain_norm.shape[1], 10):\n",
    "    \n",
    "    print(f\"Cluster: {idx}\")\n",
    "    # get subset of data which resides in cluster\n",
    "    ix = xtrain_norm\n",
    "    iy = ytrain_norm.values[:, idx]\n",
    "    print(ix.shape, iy.shape)\n",
    "#     print(ix.shape, iy.shape)\n",
    "    \n",
    "    # training and testing split\n",
    "    train_size = 0.8\n",
    "    random_state = 123\n",
    "\n",
    "    ixtrain, ixtest, iytrain, iytest = train_test_split(\n",
    "        ix, iy, train_size=train_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Standardize Inputs (per dimension)\n",
    "    x_mean, x_std = ixtrain.mean(axis=0), ixtrain.std(axis=0)\n",
    "\n",
    "    ixtrain_norm = (ixtrain - x_mean) / x_std\n",
    "    ixtest_norm = (ixtest - x_mean) / x_std\n",
    "\n",
    "    # Normalize Outputs\n",
    "    y_mean = iytrain.mean(axis=0)\n",
    "\n",
    "    iytrain_norm = iytrain - y_mean\n",
    "    iytest_norm = iytest - y_mean\n",
    "    \n",
    "    # =======================\n",
    "    # PCA\n",
    "    # =======================\n",
    "    n_components = 20\n",
    "\n",
    "    pca_model = PCA(n_components=n_components)\n",
    "\n",
    "    iytrain_red = pca_model.fit_transform(iytrain_norm)\n",
    "    iytest_red = pca_model.transform(iytest_norm)\n",
    "    \n",
    "    # =======================\n",
    "    # ML Algorithm\n",
    "    # =======================\n",
    "    rf_model = RandomForestRegressor(\n",
    "    n_estimators=1000, \n",
    "    criterion='mse',\n",
    "    n_jobs=-1,\n",
    "    random_state=123,\n",
    "    warm_start=False,\n",
    "    verbose=0\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    rf_model.fit(ixtrain_norm, iytrain_red)\n",
    "    t1 = time.time() - t0\n",
    "\n",
    "    print(\n",
    "        f\"Training Time: {t1:.3f} seconds\"\n",
    "    )\n",
    "    \n",
    "    # Predictions\n",
    "    t0 = time.time()\n",
    "    iypred_red = rf_model.predict(ixtest_norm)\n",
    "    t1 = time.time() - t0\n",
    "    iypred = pca_model.inverse_transform(iypred_red)\n",
    "\n",
    "\n",
    "    # Get Average Stats\n",
    "    mae = mean_absolute_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    mse = mean_squared_error(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(iytest_norm, iypred, multioutput='uniform_average')\n",
    "    print(\n",
    "        f\"MAE: {mae:.3f}\\nMSE: {mse:.3f}\\nRMSE: {rmse:.3f}\\nR2: {r2:.3f}\" \n",
    "        f\" \\nTime: {t1:.3} seconds\"\n",
    "    )\n",
    "    print(\"Done!\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-2019_ml_ocean]",
   "language": "python",
   "name": "conda-env-.conda-2019_ml_ocean-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
